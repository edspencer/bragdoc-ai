# Corpus Testing Directory

This directory contains the corpus testing infrastructure for BragDoc. Corpus testing enables regression testing of LLM-powered features by capturing inputs, running them through prompts, and comparing outputs against expected results.

## Directory Structure

```
corpus/
├── README.md           # This file
├── manifest.json       # Registry of all corpus tests
├── snapshots/          # Input snapshots for testing
│   └── .gitkeep
└── reports/            # Test execution reports
    └── .gitkeep
```

## Directories

### `snapshots/`

Contains input snapshots organized by feature area. Each snapshot captures real or representative data that can be used to test LLM prompt behavior.

Example structure:
```
snapshots/
├── achievement-extraction/
│   ├── git-commits/
│   └── github-prs/
├── document-generation/
│   └── weekly-reports/
└── workstream-clustering/
    └── achievement-sets/
```

### `reports/`

Contains test execution reports generated by corpus test runs. Reports include:
- Test results (pass/fail/regression)
- Output comparisons
- Performance metrics
- Timestamps and metadata

## Cache Directory

The `.corpus-cache/` directory (gitignored) stores:
- Cached LLM responses for deterministic testing
- Temporary test artifacts
- Intermediate processing results

## Usage

Corpus tests are run via dedicated skills:

- `/corpus-capture` - Capture new input snapshots
- `/corpus-test` - Run tests against snapshots
- `/corpus-report` - Generate test reports

## manifest.json

The manifest file tracks all registered corpus tests:

```json
{
  "version": "1.0.0",
  "description": "BragDoc corpus testing manifest",
  "snapshots": [
    {
      "id": "achievement-extraction-001",
      "feature": "achievement-extraction",
      "input": "snapshots/achievement-extraction/git-commits/sample-001.json",
      "expected": "snapshots/achievement-extraction/git-commits/sample-001.expected.json"
    }
  ],
  "reports": []
}
```

## Adding New Corpus Tests

1. Capture representative input data
2. Place in appropriate `snapshots/` subdirectory
3. Generate expected output (manually verified)
4. Register in `manifest.json`
5. Run tests to establish baseline
