# Meta Performance Review Process

> Last researched: 2025-01-15
> Confidence: High - Multiple detailed sources with consistent information

## Overview

Meta uses the **PSC (Performance Summary Cycle)** system. Originally a biannual review process, Meta has shifted to an annual review cycle with a lighter 6-month check-in process.

The PSC is a comprehensive 360-degree review involving self-review, peer feedback, upward feedback (for managers), and calibration.

## Review Cycle

- **System Name**: PSC (Performance Summary Cycle)
- **Frequency**: Annual (was biannual), with lighter 6-month check-ins
- **Timing**: January and July cycles historically; now primarily annual
- **Eligibility**: Not specified publicly

## Self-Review

### Format

Free-form self-review organized by four performance axes. The self-review is consolidated into a calibration package that your manager presents during calibration meetings.

### Questions

Your self-review should be segmented into the four evaluation axes (see below). For each axis, describe your contributions and impact.

There is no single question prompt - you write a comprehensive assessment covering all axes.

### Character/Word Limits

- **Self-review length**: 500 - 1,500 words total
- **Peer feedback**: ~250 words recommended

### Supporting Materials

Include links to supporting evidence:
- Code diffs
- Workplace posts
- Design documents
- Launch announcements
- Metrics dashboards

## Evaluation Axes

Engineers are evaluated on four axes:

1. **Project Impact** - The business results you drove
   - Projects and experiments that shipped
   - Quantifiable outcomes (metrics, revenue, user impact)
   - Most engineers have the most to discuss in this section

2. **Direction** - Influencing the work done by others
   - Strategy and priorities at team, org, or company level
   - This axis becomes increasingly important at Senior+ levels
   - Less critical for junior engineers

3. **Engineering Excellence** - Technical quality
   - Work done to design better systems
   - Improving developer velocity
   - Reducing and fixing bugs
   - Code quality and architecture

4. **People** - Non-technical contributions
   - Mentorship
   - Conducting interviews
   - Onboarding new team members
   - Also known as "organizational impact"

## Peer Feedback

### Format

360-degree peer review process.

### Process

1. Request feedback from 3-5 peers
2. Write peer feedback for others who request it
3. Write upward feedback for your manager

### Limits

- Number of reviewers: 3-5 peers (you select them)
- Word limit: ~250 words recommended, but can write more
- Anonymity: Feedback is shared but attributed

### Manager Feedback Questions

Employees provide feedback on their manager with questions like:

1. **"How did your manager unblock your work and make the team more productive?"**

2. **"How does the manager encourage diverse perspectives?"**

This upward feedback is revealed to managers after calibrations are complete (approximately 2 months later).

## Calibration & Ratings

### Process

1. Manager creates a calibration package from self-review and peer feedback
2. Manager proposes a rating
3. Calibration meetings held by engineering level (all L4s together, all L5s together, etc.)
4. Manager gives 1-2 minute summary of each engineer's impact
5. Others ask questions and compare to previously discussed engineers
6. Ratings adjusted for fairness
7. Final ratings sent up the chain for VP approval
8. VP may force adjustments based on budget considerations

### Stack Ranking

Meta doesn't enforce strict distribution at the team level, but there are expectations for certain percentage breakdowns within larger orgs.

### Rating Scale

| Rating | Abbreviation | Bonus Multiplier |
|--------|--------------|------------------|
| Does Not Meet Expectations | DNE | 0% |
| Meets Some | MS | 0% |
| Meets Most | MM | 85% |
| Meets All | MA | 100% |
| Exceeds Expectations | EE | 125% |
| Greatly Exceeds | GE | 200% |
| Redefines Expectations | RE | 300% |

The bonus multiplier applies to both cash and RSU bonuses.

## Tips for Success

### What High Performers Do

- **Include evidence**: Link to diffs, posts, and metrics throughout your self-review
- **Quantify impact**: Use specific numbers and percentages
- **Address all axes**: Even if one is light, acknowledge it
- **Request strategic peer feedback**: Choose peers who saw your most impactful work
- **Document throughout the cycle**: Don't wait until review time

### Common Mistakes to Avoid

- Writing too little (under 500 words lacks depth)
- Writing too much (over 1,500 words suggests inability to prioritize)
- Focusing only on Project Impact at senior levels (Direction matters more)
- Not including supporting links and evidence
- Choosing peer reviewers who didn't see your best work

## Sources

- [TeamRora - Meta Performance Review](https://www.teamrora.com/post/meta-performance-review)
- [Promotions.fyi - Meta Performance Review](https://www.promotions.fyi/company/meta/performance-review)
- [AgilityPortal - Facebook PSC Cycle](https://agilityportal.io/blog/facebook-psc-cycle-updated-2022-pip-culture-psc-levels-more)
- [Taro - Meta Performance Review](https://www.jointaro.com/topic/meta/performance-review/)
- [Automation Hacks - Engineering Practices at Meta](https://newsletter.automationhacks.io/p/engineering-practices-meta-8-performance)

## Gaps in Research

- Exact question prompts from the internal system
- Specific character limits (only word guidance available)
- Details on the 6-month check-in process
- Exact calibration meeting agenda
